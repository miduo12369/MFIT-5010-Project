{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### import data #####\n",
    "# add a new column with value = 1 for train positive  \n",
    "train_pos = pd.read_csv('/Users/liuruoxue/Downloads/train_pos.csv')\n",
    "train_pos[\"sentiment\"] = \"1\"\n",
    "#train_pos.to_csv(\"/Users/liuruoxue/Downloads/train_pos.csv\", index = False)\n",
    "\n",
    "# add a new column with value = 0 for train negative \n",
    "train_neg = pd.read_csv('/Users/liuruoxue/Downloads/train_neg.csv')\n",
    "train_neg[\"sentiment\"] = \"0\"\n",
    "#train_neg.to_csv(\"/Users/liuruoxue/Downloads/train_neg.csv\", index = False)\n",
    "\n",
    "# add a new column with value = 1 for test positive \n",
    "test_pos = pd.read_csv('/Users/liuruoxue/Downloads/test_pos.csv')\n",
    "test_pos[\"sentiment\"] = \"1\"\n",
    "#test_pos.to_csv(\"/Users/liuruoxue/Downloads/test_pos.csv\", index = False)\n",
    "\n",
    "# add a new column with value = 0 for test negative \n",
    "test_neg = pd.read_csv('/Users/liuruoxue/Downloads/test_neg.csv')\n",
    "test_neg[\"sentiment\"] = \"0\"\n",
    "#test_neg.to_csv(\"/Users/liuruoxue/Downloads/train_neg.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# combine the train positive and train negative data \n",
    "train = [train_pos, train_neg]\n",
    "train = pd.concat(train, ignore_index = True)\n",
    "\n",
    "# combine the test positive and test negative data \n",
    "test = [test_pos, test_neg]\n",
    "test = pd.concat(test, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12500\n",
       "1    12500\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school, work, or vote for the matter. Most people think of the homeless as just a lost cause while worrying about things such as racism, the war on Iraq, pressuring kids to succeed, technology, the elections, inflation, or worrying if they\\'ll be next to end up on the streets.<br /><br />But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home, the entertainment sets, a bathroom, pictures on the wall, a computer, and everything you once treasure to see what it\\'s like to be homeless? That is Goddard Bolt\\'s lesson.<br /><br />Mel Brooks (who directs) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival (Jeffery Tambor) to see if he can live in the streets for thirty days without the luxuries; if Bolt succeeds, he can do what he wants with a future project of making more buildings. The bet\\'s on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can\\'t step off the sidewalk. He\\'s given the nickname Pepto by a vagrant after it\\'s written on his forehead where Bolt meets other characters including a woman by the name of Molly (Lesley Ann Warren) an ex-dancer who got divorce before losing her home, and her pals Sailor (Howard Morris) and Fumes (Teddy Wilson) who are already used to the streets. They\\'re survivors. Bolt isn\\'t. He\\'s not used to reaching mutual agreements like he once did when being rich where it\\'s fight or flight, kill or be killed.<br /><br />While the love connection between Molly and Bolt wasn\\'t necessary to plot, I found \"Life Stinks\" to be one of Mel Brooks\\' observant films where prior to being a comedy, it shows a tender side compared to his slapstick work such as Blazing Saddles, Young Frankenstein, or Spaceballs for the matter, to show what it\\'s like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don\\'t know what to do with their money. Maybe they should give it to the homeless instead of using it like Monopoly money.<br /><br />Or maybe this film will inspire you to help others.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = train['Review'].loc[1]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school, work, or vote for the matter. Most people think of the homeless as just a lost cause while worrying about things such as racism, the war on Iraq, pressuring kids to succeed, technology, the elections, inflation, or worrying if they\\'ll be next to end up on the streets.But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home, the entertainment sets, a bathroom, pictures on the wall, a computer, and everything you once treasure to see what it\\'s like to be homeless? That is Goddard Bolt\\'s lesson.Mel Brooks (who directs) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival (Jeffery Tambor) to see if he can live in the streets for thirty days without the luxuries; if Bolt succeeds, he can do what he wants with a future project of making more buildings. The bet\\'s on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can\\'t step off the sidewalk. He\\'s given the nickname Pepto by a vagrant after it\\'s written on his forehead where Bolt meets other characters including a woman by the name of Molly (Lesley Ann Warren) an ex-dancer who got divorce before losing her home, and her pals Sailor (Howard Morris) and Fumes (Teddy Wilson) who are already used to the streets. They\\'re survivors. Bolt isn\\'t. He\\'s not used to reaching mutual agreements like he once did when being rich where it\\'s fight or flight, kill or be killed.While the love connection between Molly and Bolt wasn\\'t necessary to plot, I found \"Life Stinks\" to be one of Mel Brooks\\' observant films where prior to being a comedy, it shows a tender side compared to his slapstick work such as Blazing Saddles, Young Frankenstein, or Spaceballs for the matter, to show what it\\'s like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don\\'t know what to do with their money. Maybe they should give it to the homeless instead of using it like Monopoly money.Or maybe this film will inspire you to help others.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "soup = BeautifulSoup(review, \"html.parser\")\n",
    "review = soup.get_text()\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Homelessness  or Houselessness as George Carlin stated  has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school  work  or vote for the matter  Most people think of the homeless as just a lost cause while worrying about things such as racism  the war on Iraq  pressuring kids to succeed  technology  the elections  inflation  or worrying if they ll be next to end up on the streets But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home  the entertainment sets  a bathroom  pictures on the wall  a computer  and everything you once treasure to see what it s like to be homeless  That is Goddard Bolt s lesson Mel Brooks  who directs  who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival  Jeffery Tambor  to see if he can live in the streets for thirty days without the luxuries  if Bolt succeeds  he can do what he wants with a future project of making more buildings  The bet s on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can t step off the sidewalk  He s given the nickname Pepto by a vagrant after it s written on his forehead where Bolt meets other characters including a woman by the name of Molly  Lesley Ann Warren  an ex dancer who got divorce before losing her home  and her pals Sailor  Howard Morris  and Fumes  Teddy Wilson  who are already used to the streets  They re survivors  Bolt isn t  He s not used to reaching mutual agreements like he once did when being rich where it s fight or flight  kill or be killed While the love connection between Molly and Bolt wasn t necessary to plot  I found  Life Stinks  to be one of Mel Brooks  observant films where prior to being a comedy  it shows a tender side compared to his slapstick work such as Blazing Saddles  Young Frankenstein  or Spaceballs for the matter  to show what it s like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don t know what to do with their money  Maybe they should give it to the homeless instead of using it like Monopoly money Or maybe this film will inspire you to help others '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'homelessness  or houselessness as george carlin stated  has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school  work  or vote for the matter  most people think of the homeless as just a lost cause while worrying about things such as racism  the war on iraq  pressuring kids to succeed  technology  the elections  inflation  or worrying if they ll be next to end up on the streets but what if you were given a bet to live on the streets for a month without the luxuries you once had from a home  the entertainment sets  a bathroom  pictures on the wall  a computer  and everything you once treasure to see what it s like to be homeless  that is goddard bolt s lesson mel brooks  who directs  who stars as bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival  jeffery tambor  to see if he can live in the streets for thirty days without the luxuries  if bolt succeeds  he can do what he wants with a future project of making more buildings  the bet s on where bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can t step off the sidewalk  he s given the nickname pepto by a vagrant after it s written on his forehead where bolt meets other characters including a woman by the name of molly  lesley ann warren  an ex dancer who got divorce before losing her home  and her pals sailor  howard morris  and fumes  teddy wilson  who are already used to the streets  they re survivors  bolt isn t  he s not used to reaching mutual agreements like he once did when being rich where it s fight or flight  kill or be killed while the love connection between molly and bolt wasn t necessary to plot  i found  life stinks  to be one of mel brooks  observant films where prior to being a comedy  it shows a tender side compared to his slapstick work such as blazing saddles  young frankenstein  or spaceballs for the matter  to show what it s like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don t know what to do with their money  maybe they should give it to the homeless instead of using it like monopoly money or maybe this film will inspire you to help others '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = review.lower()\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['homelessness',\n",
       " 'or',\n",
       " 'houselessness',\n",
       " 'as',\n",
       " 'george',\n",
       " 'carlin',\n",
       " 'stated',\n",
       " 'has',\n",
       " 'been',\n",
       " 'an',\n",
       " 'issue',\n",
       " 'for',\n",
       " 'years',\n",
       " 'but',\n",
       " 'never',\n",
       " 'a',\n",
       " 'plan',\n",
       " 'to',\n",
       " 'help',\n",
       " 'those',\n",
       " 'on',\n",
       " 'the',\n",
       " 'street',\n",
       " 'that',\n",
       " 'were',\n",
       " 'once',\n",
       " 'considered',\n",
       " 'human',\n",
       " 'who',\n",
       " 'did',\n",
       " 'everything',\n",
       " 'from',\n",
       " 'going',\n",
       " 'to',\n",
       " 'school',\n",
       " 'work',\n",
       " 'or',\n",
       " 'vote',\n",
       " 'for',\n",
       " 'the',\n",
       " 'matter',\n",
       " 'most',\n",
       " 'people',\n",
       " 'think',\n",
       " 'of',\n",
       " 'the',\n",
       " 'homeless',\n",
       " 'as',\n",
       " 'just',\n",
       " 'a',\n",
       " 'lost',\n",
       " 'cause',\n",
       " 'while',\n",
       " 'worrying',\n",
       " 'about',\n",
       " 'things',\n",
       " 'such',\n",
       " 'as',\n",
       " 'racism',\n",
       " 'the',\n",
       " 'war',\n",
       " 'on',\n",
       " 'iraq',\n",
       " 'pressuring',\n",
       " 'kids',\n",
       " 'to',\n",
       " 'succeed',\n",
       " 'technology',\n",
       " 'the',\n",
       " 'elections',\n",
       " 'inflation',\n",
       " 'or',\n",
       " 'worrying',\n",
       " 'if',\n",
       " 'they',\n",
       " 'll',\n",
       " 'be',\n",
       " 'next',\n",
       " 'to',\n",
       " 'end',\n",
       " 'up',\n",
       " 'on',\n",
       " 'the',\n",
       " 'streets',\n",
       " 'but',\n",
       " 'what',\n",
       " 'if',\n",
       " 'you',\n",
       " 'were',\n",
       " 'given',\n",
       " 'a',\n",
       " 'bet',\n",
       " 'to',\n",
       " 'live',\n",
       " 'on',\n",
       " 'the',\n",
       " 'streets',\n",
       " 'for',\n",
       " 'a',\n",
       " 'month',\n",
       " 'without',\n",
       " 'the',\n",
       " 'luxuries',\n",
       " 'you',\n",
       " 'once',\n",
       " 'had',\n",
       " 'from',\n",
       " 'a',\n",
       " 'home',\n",
       " 'the',\n",
       " 'entertainment',\n",
       " 'sets',\n",
       " 'a',\n",
       " 'bathroom',\n",
       " 'pictures',\n",
       " 'on',\n",
       " 'the',\n",
       " 'wall',\n",
       " 'a',\n",
       " 'computer',\n",
       " 'and',\n",
       " 'everything',\n",
       " 'you',\n",
       " 'once',\n",
       " 'treasure',\n",
       " 'to',\n",
       " 'see',\n",
       " 'what',\n",
       " 'it',\n",
       " 's',\n",
       " 'like',\n",
       " 'to',\n",
       " 'be',\n",
       " 'homeless',\n",
       " 'that',\n",
       " 'is',\n",
       " 'goddard',\n",
       " 'bolt',\n",
       " 's',\n",
       " 'lesson',\n",
       " 'mel',\n",
       " 'brooks',\n",
       " 'who',\n",
       " 'directs',\n",
       " 'who',\n",
       " 'stars',\n",
       " 'as',\n",
       " 'bolt',\n",
       " 'plays',\n",
       " 'a',\n",
       " 'rich',\n",
       " 'man',\n",
       " 'who',\n",
       " 'has',\n",
       " 'everything',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " 'until',\n",
       " 'deciding',\n",
       " 'to',\n",
       " 'make',\n",
       " 'a',\n",
       " 'bet',\n",
       " 'with',\n",
       " 'a',\n",
       " 'sissy',\n",
       " 'rival',\n",
       " 'jeffery',\n",
       " 'tambor',\n",
       " 'to',\n",
       " 'see',\n",
       " 'if',\n",
       " 'he',\n",
       " 'can',\n",
       " 'live',\n",
       " 'in',\n",
       " 'the',\n",
       " 'streets',\n",
       " 'for',\n",
       " 'thirty',\n",
       " 'days',\n",
       " 'without',\n",
       " 'the',\n",
       " 'luxuries',\n",
       " 'if',\n",
       " 'bolt',\n",
       " 'succeeds',\n",
       " 'he',\n",
       " 'can',\n",
       " 'do',\n",
       " 'what',\n",
       " 'he',\n",
       " 'wants',\n",
       " 'with',\n",
       " 'a',\n",
       " 'future',\n",
       " 'project',\n",
       " 'of',\n",
       " 'making',\n",
       " 'more',\n",
       " 'buildings',\n",
       " 'the',\n",
       " 'bet',\n",
       " 's',\n",
       " 'on',\n",
       " 'where',\n",
       " 'bolt',\n",
       " 'is',\n",
       " 'thrown',\n",
       " 'on',\n",
       " 'the',\n",
       " 'street',\n",
       " 'with',\n",
       " 'a',\n",
       " 'bracelet',\n",
       " 'on',\n",
       " 'his',\n",
       " 'leg',\n",
       " 'to',\n",
       " 'monitor',\n",
       " 'his',\n",
       " 'every',\n",
       " 'move',\n",
       " 'where',\n",
       " 'he',\n",
       " 'can',\n",
       " 't',\n",
       " 'step',\n",
       " 'off',\n",
       " 'the',\n",
       " 'sidewalk',\n",
       " 'he',\n",
       " 's',\n",
       " 'given',\n",
       " 'the',\n",
       " 'nickname',\n",
       " 'pepto',\n",
       " 'by',\n",
       " 'a',\n",
       " 'vagrant',\n",
       " 'after',\n",
       " 'it',\n",
       " 's',\n",
       " 'written',\n",
       " 'on',\n",
       " 'his',\n",
       " 'forehead',\n",
       " 'where',\n",
       " 'bolt',\n",
       " 'meets',\n",
       " 'other',\n",
       " 'characters',\n",
       " 'including',\n",
       " 'a',\n",
       " 'woman',\n",
       " 'by',\n",
       " 'the',\n",
       " 'name',\n",
       " 'of',\n",
       " 'molly',\n",
       " 'lesley',\n",
       " 'ann',\n",
       " 'warren',\n",
       " 'an',\n",
       " 'ex',\n",
       " 'dancer',\n",
       " 'who',\n",
       " 'got',\n",
       " 'divorce',\n",
       " 'before',\n",
       " 'losing',\n",
       " 'her',\n",
       " 'home',\n",
       " 'and',\n",
       " 'her',\n",
       " 'pals',\n",
       " 'sailor',\n",
       " 'howard',\n",
       " 'morris',\n",
       " 'and',\n",
       " 'fumes',\n",
       " 'teddy',\n",
       " 'wilson',\n",
       " 'who',\n",
       " 'are',\n",
       " 'already',\n",
       " 'used',\n",
       " 'to',\n",
       " 'the',\n",
       " 'streets',\n",
       " 'they',\n",
       " 're',\n",
       " 'survivors',\n",
       " 'bolt',\n",
       " 'isn',\n",
       " 't',\n",
       " 'he',\n",
       " 's',\n",
       " 'not',\n",
       " 'used',\n",
       " 'to',\n",
       " 'reaching',\n",
       " 'mutual',\n",
       " 'agreements',\n",
       " 'like',\n",
       " 'he',\n",
       " 'once',\n",
       " 'did',\n",
       " 'when',\n",
       " 'being',\n",
       " 'rich',\n",
       " 'where',\n",
       " 'it',\n",
       " 's',\n",
       " 'fight',\n",
       " 'or',\n",
       " 'flight',\n",
       " 'kill',\n",
       " 'or',\n",
       " 'be',\n",
       " 'killed',\n",
       " 'while',\n",
       " 'the',\n",
       " 'love',\n",
       " 'connection',\n",
       " 'between',\n",
       " 'molly',\n",
       " 'and',\n",
       " 'bolt',\n",
       " 'wasn',\n",
       " 't',\n",
       " 'necessary',\n",
       " 'to',\n",
       " 'plot',\n",
       " 'i',\n",
       " 'found',\n",
       " 'life',\n",
       " 'stinks',\n",
       " 'to',\n",
       " 'be',\n",
       " 'one',\n",
       " 'of',\n",
       " 'mel',\n",
       " 'brooks',\n",
       " 'observant',\n",
       " 'films',\n",
       " 'where',\n",
       " 'prior',\n",
       " 'to',\n",
       " 'being',\n",
       " 'a',\n",
       " 'comedy',\n",
       " 'it',\n",
       " 'shows',\n",
       " 'a',\n",
       " 'tender',\n",
       " 'side',\n",
       " 'compared',\n",
       " 'to',\n",
       " 'his',\n",
       " 'slapstick',\n",
       " 'work',\n",
       " 'such',\n",
       " 'as',\n",
       " 'blazing',\n",
       " 'saddles',\n",
       " 'young',\n",
       " 'frankenstein',\n",
       " 'or',\n",
       " 'spaceballs',\n",
       " 'for',\n",
       " 'the',\n",
       " 'matter',\n",
       " 'to',\n",
       " 'show',\n",
       " 'what',\n",
       " 'it',\n",
       " 's',\n",
       " 'like',\n",
       " 'having',\n",
       " 'something',\n",
       " 'valuable',\n",
       " 'before',\n",
       " 'losing',\n",
       " 'it',\n",
       " 'the',\n",
       " 'next',\n",
       " 'day',\n",
       " 'or',\n",
       " 'on',\n",
       " 'the',\n",
       " 'other',\n",
       " 'hand',\n",
       " 'making',\n",
       " 'a',\n",
       " 'stupid',\n",
       " 'bet',\n",
       " 'like',\n",
       " 'all',\n",
       " 'rich',\n",
       " 'people',\n",
       " 'do',\n",
       " 'when',\n",
       " 'they',\n",
       " 'don',\n",
       " 't',\n",
       " 'know',\n",
       " 'what',\n",
       " 'to',\n",
       " 'do',\n",
       " 'with',\n",
       " 'their',\n",
       " 'money',\n",
       " 'maybe',\n",
       " 'they',\n",
       " 'should',\n",
       " 'give',\n",
       " 'it',\n",
       " 'to',\n",
       " 'the',\n",
       " 'homeless',\n",
       " 'instead',\n",
       " 'of',\n",
       " 'using',\n",
       " 'it',\n",
       " 'like',\n",
       " 'monopoly',\n",
       " 'money',\n",
       " 'or',\n",
       " 'maybe',\n",
       " 'this',\n",
       " 'film',\n",
       " 'will',\n",
       " 'inspire',\n",
       " 'you',\n",
       " 'to',\n",
       " 'help',\n",
       " 'others']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = review.split()\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 61]\n",
      "[nltk_data]     Connection refused>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['homelessness',\n",
       " 'houselessness',\n",
       " 'george',\n",
       " 'carlin',\n",
       " 'stated',\n",
       " 'issue',\n",
       " 'years',\n",
       " 'never',\n",
       " 'plan',\n",
       " 'help',\n",
       " 'street',\n",
       " 'considered',\n",
       " 'human',\n",
       " 'everything',\n",
       " 'going',\n",
       " 'school',\n",
       " 'work',\n",
       " 'vote',\n",
       " 'matter',\n",
       " 'people',\n",
       " 'think',\n",
       " 'homeless',\n",
       " 'lost',\n",
       " 'cause',\n",
       " 'worrying',\n",
       " 'things',\n",
       " 'racism',\n",
       " 'war',\n",
       " 'iraq',\n",
       " 'pressuring',\n",
       " 'kids',\n",
       " 'succeed',\n",
       " 'technology',\n",
       " 'elections',\n",
       " 'inflation',\n",
       " 'worrying',\n",
       " 'next',\n",
       " 'end',\n",
       " 'streets',\n",
       " 'given',\n",
       " 'bet',\n",
       " 'live',\n",
       " 'streets',\n",
       " 'month',\n",
       " 'without',\n",
       " 'luxuries',\n",
       " 'home',\n",
       " 'entertainment',\n",
       " 'sets',\n",
       " 'bathroom',\n",
       " 'pictures',\n",
       " 'wall',\n",
       " 'computer',\n",
       " 'everything',\n",
       " 'treasure',\n",
       " 'see',\n",
       " 'like',\n",
       " 'homeless',\n",
       " 'goddard',\n",
       " 'bolt',\n",
       " 'lesson',\n",
       " 'mel',\n",
       " 'brooks',\n",
       " 'directs',\n",
       " 'stars',\n",
       " 'bolt',\n",
       " 'plays',\n",
       " 'rich',\n",
       " 'man',\n",
       " 'everything',\n",
       " 'world',\n",
       " 'deciding',\n",
       " 'make',\n",
       " 'bet',\n",
       " 'sissy',\n",
       " 'rival',\n",
       " 'jeffery',\n",
       " 'tambor',\n",
       " 'see',\n",
       " 'live',\n",
       " 'streets',\n",
       " 'thirty',\n",
       " 'days',\n",
       " 'without',\n",
       " 'luxuries',\n",
       " 'bolt',\n",
       " 'succeeds',\n",
       " 'wants',\n",
       " 'future',\n",
       " 'project',\n",
       " 'making',\n",
       " 'buildings',\n",
       " 'bet',\n",
       " 'bolt',\n",
       " 'thrown',\n",
       " 'street',\n",
       " 'bracelet',\n",
       " 'leg',\n",
       " 'monitor',\n",
       " 'every',\n",
       " 'move',\n",
       " 'step',\n",
       " 'sidewalk',\n",
       " 'given',\n",
       " 'nickname',\n",
       " 'pepto',\n",
       " 'vagrant',\n",
       " 'written',\n",
       " 'forehead',\n",
       " 'bolt',\n",
       " 'meets',\n",
       " 'characters',\n",
       " 'including',\n",
       " 'woman',\n",
       " 'name',\n",
       " 'molly',\n",
       " 'lesley',\n",
       " 'ann',\n",
       " 'warren',\n",
       " 'ex',\n",
       " 'dancer',\n",
       " 'got',\n",
       " 'divorce',\n",
       " 'losing',\n",
       " 'home',\n",
       " 'pals',\n",
       " 'sailor',\n",
       " 'howard',\n",
       " 'morris',\n",
       " 'fumes',\n",
       " 'teddy',\n",
       " 'wilson',\n",
       " 'already',\n",
       " 'used',\n",
       " 'streets',\n",
       " 'survivors',\n",
       " 'bolt',\n",
       " 'used',\n",
       " 'reaching',\n",
       " 'mutual',\n",
       " 'agreements',\n",
       " 'like',\n",
       " 'rich',\n",
       " 'fight',\n",
       " 'flight',\n",
       " 'kill',\n",
       " 'killed',\n",
       " 'love',\n",
       " 'connection',\n",
       " 'molly',\n",
       " 'bolt',\n",
       " 'necessary',\n",
       " 'plot',\n",
       " 'found',\n",
       " 'life',\n",
       " 'stinks',\n",
       " 'one',\n",
       " 'mel',\n",
       " 'brooks',\n",
       " 'observant',\n",
       " 'films',\n",
       " 'prior',\n",
       " 'comedy',\n",
       " 'shows',\n",
       " 'tender',\n",
       " 'side',\n",
       " 'compared',\n",
       " 'slapstick',\n",
       " 'work',\n",
       " 'blazing',\n",
       " 'saddles',\n",
       " 'young',\n",
       " 'frankenstein',\n",
       " 'spaceballs',\n",
       " 'matter',\n",
       " 'show',\n",
       " 'like',\n",
       " 'something',\n",
       " 'valuable',\n",
       " 'losing',\n",
       " 'next',\n",
       " 'day',\n",
       " 'hand',\n",
       " 'making',\n",
       " 'stupid',\n",
       " 'bet',\n",
       " 'like',\n",
       " 'rich',\n",
       " 'people',\n",
       " 'know',\n",
       " 'money',\n",
       " 'maybe',\n",
       " 'give',\n",
       " 'homeless',\n",
       " 'instead',\n",
       " 'using',\n",
       " 'like',\n",
       " 'monopoly',\n",
       " 'money',\n",
       " 'maybe',\n",
       " 'film',\n",
       " 'inspire',\n",
       " 'help',\n",
       " 'others']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 61]\n",
      "[nltk_data]     Connection refused>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['homelessness',\n",
       " 'houselessness',\n",
       " 'george',\n",
       " 'carlin',\n",
       " 'stated',\n",
       " 'issue',\n",
       " 'year',\n",
       " 'never',\n",
       " 'plan',\n",
       " 'help',\n",
       " 'street',\n",
       " 'considered',\n",
       " 'human',\n",
       " 'everything',\n",
       " 'going',\n",
       " 'school',\n",
       " 'work',\n",
       " 'vote',\n",
       " 'matter',\n",
       " 'people',\n",
       " 'think',\n",
       " 'homeless',\n",
       " 'lost',\n",
       " 'cause',\n",
       " 'worrying',\n",
       " 'thing',\n",
       " 'racism',\n",
       " 'war',\n",
       " 'iraq',\n",
       " 'pressuring',\n",
       " 'kid',\n",
       " 'succeed',\n",
       " 'technology',\n",
       " 'election',\n",
       " 'inflation',\n",
       " 'worrying',\n",
       " 'next',\n",
       " 'end',\n",
       " 'street',\n",
       " 'given',\n",
       " 'bet',\n",
       " 'live',\n",
       " 'street',\n",
       " 'month',\n",
       " 'without',\n",
       " 'luxury',\n",
       " 'home',\n",
       " 'entertainment',\n",
       " 'set',\n",
       " 'bathroom',\n",
       " 'picture',\n",
       " 'wall',\n",
       " 'computer',\n",
       " 'everything',\n",
       " 'treasure',\n",
       " 'see',\n",
       " 'like',\n",
       " 'homeless',\n",
       " 'goddard',\n",
       " 'bolt',\n",
       " 'lesson',\n",
       " 'mel',\n",
       " 'brook',\n",
       " 'directs',\n",
       " 'star',\n",
       " 'bolt',\n",
       " 'play',\n",
       " 'rich',\n",
       " 'man',\n",
       " 'everything',\n",
       " 'world',\n",
       " 'deciding',\n",
       " 'make',\n",
       " 'bet',\n",
       " 'sissy',\n",
       " 'rival',\n",
       " 'jeffery',\n",
       " 'tambor',\n",
       " 'see',\n",
       " 'live',\n",
       " 'street',\n",
       " 'thirty',\n",
       " 'day',\n",
       " 'without',\n",
       " 'luxury',\n",
       " 'bolt',\n",
       " 'succeeds',\n",
       " 'want',\n",
       " 'future',\n",
       " 'project',\n",
       " 'making',\n",
       " 'building',\n",
       " 'bet',\n",
       " 'bolt',\n",
       " 'thrown',\n",
       " 'street',\n",
       " 'bracelet',\n",
       " 'leg',\n",
       " 'monitor',\n",
       " 'every',\n",
       " 'move',\n",
       " 'step',\n",
       " 'sidewalk',\n",
       " 'given',\n",
       " 'nickname',\n",
       " 'pepto',\n",
       " 'vagrant',\n",
       " 'written',\n",
       " 'forehead',\n",
       " 'bolt',\n",
       " 'meet',\n",
       " 'character',\n",
       " 'including',\n",
       " 'woman',\n",
       " 'name',\n",
       " 'molly',\n",
       " 'lesley',\n",
       " 'ann',\n",
       " 'warren',\n",
       " 'ex',\n",
       " 'dancer',\n",
       " 'got',\n",
       " 'divorce',\n",
       " 'losing',\n",
       " 'home',\n",
       " 'pal',\n",
       " 'sailor',\n",
       " 'howard',\n",
       " 'morris',\n",
       " 'fume',\n",
       " 'teddy',\n",
       " 'wilson',\n",
       " 'already',\n",
       " 'used',\n",
       " 'street',\n",
       " 'survivor',\n",
       " 'bolt',\n",
       " 'used',\n",
       " 'reaching',\n",
       " 'mutual',\n",
       " 'agreement',\n",
       " 'like',\n",
       " 'rich',\n",
       " 'fight',\n",
       " 'flight',\n",
       " 'kill',\n",
       " 'killed',\n",
       " 'love',\n",
       " 'connection',\n",
       " 'molly',\n",
       " 'bolt',\n",
       " 'necessary',\n",
       " 'plot',\n",
       " 'found',\n",
       " 'life',\n",
       " 'stink',\n",
       " 'one',\n",
       " 'mel',\n",
       " 'brook',\n",
       " 'observant',\n",
       " 'film',\n",
       " 'prior',\n",
       " 'comedy',\n",
       " 'show',\n",
       " 'tender',\n",
       " 'side',\n",
       " 'compared',\n",
       " 'slapstick',\n",
       " 'work',\n",
       " 'blazing',\n",
       " 'saddle',\n",
       " 'young',\n",
       " 'frankenstein',\n",
       " 'spaceballs',\n",
       " 'matter',\n",
       " 'show',\n",
       " 'like',\n",
       " 'something',\n",
       " 'valuable',\n",
       " 'losing',\n",
       " 'next',\n",
       " 'day',\n",
       " 'hand',\n",
       " 'making',\n",
       " 'stupid',\n",
       " 'bet',\n",
       " 'like',\n",
       " 'rich',\n",
       " 'people',\n",
       " 'know',\n",
       " 'money',\n",
       " 'maybe',\n",
       " 'give',\n",
       " 'homeless',\n",
       " 'instead',\n",
       " 'using',\n",
       " 'like',\n",
       " 'monopoly',\n",
       " 'money',\n",
       " 'maybe',\n",
       " 'film',\n",
       " 'inspire',\n",
       " 'help',\n",
       " 'others']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lem = WordNetLemmatizer()\n",
    "review = [lem.lemmatize(word) for word in review]\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'homelessness houselessness george carlin stated issue year never plan help street considered human everything going school work vote matter people think homeless lost cause worrying thing racism war iraq pressuring kid succeed technology election inflation worrying next end street given bet live street month without luxury home entertainment set bathroom picture wall computer everything treasure see like homeless goddard bolt lesson mel brook directs star bolt play rich man everything world deciding make bet sissy rival jeffery tambor see live street thirty day without luxury bolt succeeds want future project making building bet bolt thrown street bracelet leg monitor every move step sidewalk given nickname pepto vagrant written forehead bolt meet character including woman name molly lesley ann warren ex dancer got divorce losing home pal sailor howard morris fume teddy wilson already used street survivor bolt used reaching mutual agreement like rich fight flight kill killed love connection molly bolt necessary plot found life stink one mel brook observant film prior comedy show tender side compared slapstick work blazing saddle young frankenstein spaceballs matter show like something valuable losing next day hand making stupid bet like rich people know money maybe give homeless instead using like monopoly money maybe film inspire help others'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = ' '.join(review)\n",
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['homelessness houselessness george carlin stated issue year never plan help street considered human everything going school work vote matter people think homeless lost cause worrying thing racism war iraq pressuring kid succeed technology election inflation worrying next end street given bet live street month without luxury home entertainment set bathroom picture wall computer everything treasure see like homeless goddard bolt lesson mel brook directs star bolt play rich man everything world deciding make bet sissy rival jeffery tambor see live street thirty day without luxury bolt succeeds want future project making building bet bolt thrown street bracelet leg monitor every move step sidewalk given nickname pepto vagrant written forehead bolt meet character including woman name molly lesley ann warren ex dancer got divorce losing home pal sailor howard morris fume teddy wilson already used street survivor bolt used reaching mutual agreement like rich fight flight kill killed love connection molly bolt necessary plot found life stink one mel brook observant film prior comedy show tender side compared slapstick work blazing saddle young frankenstein spaceballs matter show like something valuable losing next day hand making stupid bet like rich people know money maybe give homeless instead using like monopoly money maybe film inspire help others']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 4, 1, 7, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n",
       "        1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1,\n",
       "        2, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        5, 2, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1,\n",
       "        1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2,\n",
       "        1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vec = CountVectorizer()\n",
    "review_count_vec = count_vec.fit_transform(corpus)\n",
    "\n",
    "review_count_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vec_bin = CountVectorizer(binary=True)\n",
    "review_count_vec_bin = count_vec_bin.fit_transform(corpus)\n",
    "\n",
    "review_count_vec_bin.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.20739034,\n",
       "        0.05184758, 0.36293309, 0.05184758, 0.10369517, 0.05184758,\n",
       "        0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.10369517,\n",
       "        0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.05184758, 0.05184758, 0.15554275, 0.05184758, 0.05184758,\n",
       "        0.10369517, 0.05184758, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.10369517,\n",
       "        0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.10369517,\n",
       "        0.10369517, 0.15554275, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.05184758, 0.25923792, 0.10369517, 0.10369517, 0.05184758,\n",
       "        0.05184758, 0.10369517, 0.05184758, 0.10369517, 0.05184758,\n",
       "        0.10369517, 0.10369517, 0.05184758, 0.10369517, 0.10369517,\n",
       "        0.10369517, 0.05184758, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.10369517, 0.05184758, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.05184758, 0.10369517, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.05184758, 0.05184758, 0.15554275, 0.05184758, 0.05184758,\n",
       "        0.05184758, 0.05184758, 0.10369517, 0.05184758, 0.10369517,\n",
       "        0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.31108551, 0.05184758, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.10369517,\n",
       "        0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.05184758,\n",
       "        0.05184758, 0.05184758, 0.05184758, 0.05184758, 0.10369517,\n",
       "        0.05184758, 0.10369517, 0.05184758, 0.10369517, 0.05184758,\n",
       "        0.05184758, 0.05184758]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "review_tfidf_vec = tfidf_vec.fit_transform(corpus)\n",
    "\n",
    "review_tfidf_vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-a63d0bd05bc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mlem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-a63d0bd05bc9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreview\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mlem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mreview\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreview\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36mwords\u001b[0;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \"\"\"\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_lines_startswith\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         return [line for line in line_tokenize(self.raw(fileids))\n\u001b[0m\u001b[1;32m     23\u001b[0m                 if not line.startswith(ignore_lines_startswith)]\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36mraw\u001b[0;34m(self, fileids)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/wordlist.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fileids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfileids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/api.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, file)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \"\"\"\n\u001b[1;32m    212\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, encoding)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeekableUnicodeStreamReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "corpus_train = []\n",
    "corpus_test  = []\n",
    "#train.shape[0]\n",
    "for i in range(train.shape[0]):\n",
    "    soup = BeautifulSoup(train.iloc[i][0], \"html.parser\")\n",
    "    review = soup.get_text()\n",
    "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "    lem = WordNetLemmatizer()\n",
    "    review = [lem.lemmatize(word) for word in review]\n",
    "    review = ' '.join(review)\n",
    "    corpus_train.append(review)\n",
    "#test.shape[0]  \n",
    "for j in range(test.shape[0]):\n",
    "    soup = BeautifulSoup(test.iloc[j][0], \"html.parser\")\n",
    "    review = soup.get_text()\n",
    "    review = re.sub('\\[[^]]*\\]', ' ', review)\n",
    "    review = re.sub('[^a-zA-Z]', ' ', review)\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "    lem = WordNetLemmatizer()\n",
    "    review = [lem.lemmatize(word) for word in review]\n",
    "    review = ' '.join(review)\n",
    "    corpus_test.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train1=pd.DataFrame(corpus_train)\n",
    "corpus_test1=pd.DataFrame(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 3557)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-12e77117a1f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtfidf_vec_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtfidf_vec_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, raw_documents, copy)\u001b[0m\n\u001b[1;32m   1679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1300\u001b[0m         \u001b[0mvectors\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0msparse\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m         \"\"\"\n\u001b[0;32m-> 1302\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    548\u001b[0m                              \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[0;32m--> 550\u001b[0;31m                                 context))\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 3557)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "tfidf_vec = TfidfVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "tfidf_vec_train = tfidf_vec.fit_transform(corpus_train)\n",
    "tfidf_vec_test = tfidf_vec.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "linear_svc = LinearSVC(C=0.5, random_state=42)\n",
    "linear_svc.fit(tfidf_vec_train,train['sentiment'])\n",
    "\n",
    "predict = linear_svc.predict(tfidf_vec_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"Classification Report: \\n\", classification_report(test['sentiment'], predict,target_names=['Negative','Positive']))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(test['sentiment'], predict))\n",
    "print(\"Accuracy: \\n\", accuracy_score(test['sentiment'], predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vec_NB = TfidfVectorizer(ngram_range=(1, 1))\n",
    "tfidf_vec_train_NB = tfidf_vec_NB.fit_transform(corpus_train)\n",
    "\n",
    "tfidf_vec_test_NB = tfidf_vec_NB.transform(corpus_test)\n",
    "\n",
    "print(tfidf_vec_train_NB.toarray().shape, tfidf_vec_test_NB.toarray().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "ch2 = SelectKBest(chi2, k=50000)\n",
    "tfidf_vec_train_NB = ch2.fit_transform(tfidf_vec_train_NB, train['sentiment'])\n",
    "tfidf_vec_test_NB  = ch2.transform(tfidf_vec_test_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf_vec_NB.get_feature_names()\n",
    "feature_names = [feature_names[i] for i\n",
    "                         in ch2.get_support(indices=True)]\n",
    "feature_names = np.asarray(feature_names)\n",
    "feature_names[32245]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "multi_clf = MultinomialNB()\n",
    "multi_clf.fit(tfidf_vec_train_NB, train['sentiment'])\n",
    "\n",
    "predict_NB = multi_clf.predict(tfidf_vec_test_NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Report: \\n\", classification_report(test['sentiment'], predict_NB,target_names=['Negative','Positive']))\n",
    "print(\"Confusion Matrix: \\n\", confusion_matrix(test['sentiment'], predict_NB))\n",
    "print(\"Accuracy: \\n\", accuracy_score(test['sentiment'], predict_NB))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
